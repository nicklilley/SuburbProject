{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'target_data//suburbdatatest.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\Other computers\\Nicks 2021 PC\\Google Drive Computer Sync\\Github\\SuburbProject\\extract_and_load\\EL_apidomainonline.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/Nicks%202021%20PC/Google%20Drive%20Computer%20Sync/Github/SuburbProject/extract_and_load/EL_apidomainonline.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loop_run_log \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/Nicks%202021%20PC/Google%20Drive%20Computer%20Sync/Github/SuburbProject/extract_and_load/EL_apidomainonline.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#import api_call_target_id, state, suburb and postcodes into dataframe\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Other%20computers/Nicks%202021%20PC/Google%20Drive%20Computer%20Sync/Github/SuburbProject/extract_and_load/EL_apidomainonline.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mtarget_data//suburbdatatest.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/Nicks%202021%20PC/Google%20Drive%20Computer%20Sync/Github/SuburbProject/extract_and_load/EL_apidomainonline.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m\"\u001b[39m\u001b[39mapi_call_target_id\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mbetween(start_iterating,stop_iterating)] \u001b[39m#filter by api_call_target_id\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Other%20computers/Nicks%202021%20PC/Google%20Drive%20Computer%20Sync/Github/SuburbProject/extract_and_load/EL_apidomainonline.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#Convert dataframe into lists\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'target_data//suburbdatatest.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Import packages and secrets\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",

    "import botocore\n",
    "import pyarrow\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from datetime import datetime\n",
    "from config import api_key_secret, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\n",
    "from aws_secretsmanager_caching import SecretCache, SecretCacheConfig \n",
    "\n",
    "############################################################################\n",
    "###### SET API TARGET, PARAMETERS, DESTINATION BUCKET AND LOGGING ##########\n",
    "############################################################################\n",
    "\n",
    "# Set API Target and Parameters\n",
    "base_url = \"https://api.domain.com.au\"\n",
    "version = \"v2\"\n",
    "year = \"2016\"\n",
    "api_name = \"suburbPerformanceStatistics\"\n",
    "property_types = [\"House\",\"Unit\"]\n",
    "period_size = 'Quarters'\n",
    "total_periods = '100'\n",
    "header = {\"X-API-Key\" : api_key_secret} #Authentication\n",
    "\n",
    "# Set Destination S3 bucket variables\n",
    "s3 = boto3.client('s3')\n",
    "jsonbucket = 'sbx-apidomainonline-injest-json'\n",
    "parquetbucket = 'sbx-apidomainonline-injest-parquet'\n",
    "\n",

    "# Create empty list of lists to capture details for each successful loop run\n",
    "loop_log = []\n",
    "\n",
    "############################################################################\n",
    "############### GET LIST OF SEEDS FOR API CALL FROM SNOWFLAKE ##############\n",
    "############################################################################\n",
    "\n",
    "# Get secrets from AWS Secrets Manager\n",
    "client = botocore.session.get_session().create_client('secretsmanager')\n",
    "cache_config = SecretCacheConfig()\n",
    "cache = SecretCache( config = cache_config, client = client)\n",
    "secrets = cache.get_secret_string('snowflake-creds')\n",
    "secrets = (json.loads(secrets)) #Put secrets into a dictionary\n",
    "\n",
    "# Initialize connection to Snowflake\n",
    "ctx = snowflake.connector.connect(\n",
    "    user='NICKLILLEYMAN',\n",
    "    password=(secrets['password']),\n",
    "    account=(secrets['account']),\n",
    "    region =(secrets['region']),\n",
    "    warehouse=(secrets['warehouse']),\n",
    "    database='SBX_RAW',\n",
    "    schema='PUBLIC'\n",
    "    )\n",
    "\n",
    "# Create a cursor object.\n",
    "cur = ctx.cursor()\n",
    "\n",
    "# Execute SQL to get list of seeds from dim_suburb_geography, minus any seeds already executed in previous runs (see api_call_log table)\n",
    "seed_table = \"SBX_ANALYTICS.DBT_NLILLEYMAN_COMMON.DIM_SUBURB_GEOGRAPHY\"\n",
    "sql = (\"\"\"\n",
    "SELECT\n",
    "    DIM_SUBURB_SK\n",
    "    ,SUBURB_ID\n",
    "    ,SUBURB\n",
    "    ,POSTCODE\n",
    "    ,STATE\n",
    "FROM %(seed_table)s\n",
    "WHERE\n",
    "    STATE = 'WA'\n",
    "    AND  CONCAT('%(api_name)s','-',DIM_SUBURB_SK) NOT IN (SELECT SEED_KEY FROM SBX_RAW.PUBLIC.API_CALL_LOG)\n",
    "  --AND SUBURB in ('Willetton','Brentwood','Harrisdale','Leeming')\n",
    "ORDER BY DIM_SUBURB_SK\n",
    "\"\"\" % {\"seed_table\": seed_table,\"api_name\": api_name})\n",
    "cur.execute(sql)\n",
    "if cur.rowcount == 0:\n",
    "    print(\"No seeds to process\")\n",
    "\n",
    "# Put query results into a dataframe and restrict dataframe to limit API calls\n",
    "df = cur.fetch_pandas_all()\n",
    "df['api_call_target_id'] = df.reset_index().index #Create row number for iterator\n",
    "start_iterating = 0\n",
    "stop_iterating = start_iterating + 10\n",
    "df = df.loc[df[\"api_call_target_id\"].between(start_iterating,stop_iterating)] #restict dataframe\n",
    "\n",
    "#Convert dataframe to lists\n",
    "api_call_target_ids = ((df[\"api_call_target_id\"]).astype(str).tolist())  #convert df to string and then convert to list\n",
    "dim_suburb_sks = (df[\"DIM_SUBURB_SK\"]).tolist()\n",
    "states = (df[\"STATE\"]).tolist()\n",
    "suburbs = (df[\"SUBURB\"]).tolist()\n",
    "postcodes = ((df[\"POSTCODE\"]).astype(str).tolist()) #convert df to string and then convert to list\n",
    "\n",
    "\n",
    "############################################################################\n",
    "############### LOOP THROUGH SEEDS AND CALL API FOR EACH SEED ##############\n",
    "############################################################################\n",
    "\n",
    "# Loop through each item in lists, construct request URL, output JSON and parquet, log results\n",
    "for i in property_types:\n",
    "    property_types = i\n",
    "    for api_call_target_id,state,suburb,postcode,dim_suburb_sk in zip(api_call_target_ids,states,suburbs,postcodes,dim_suburb_sks):    \n",
    "        try:\n",
    "            #Define metadata variables\n",
    "            api_call_datetime = datetime.now()\n",
    "            seed_key = api_name+'-'+dim_suburb_sk\n",
    "            full_url = base_url+\"/\"+version+\"/\"+api_name+\"/\"+str(state)+\"/\"+str(suburb)+\"/\"+str(postcode)+\"?propertyCategory=\"+str(property_types)+\"&periodSize=\"+str(period_size)+\"&totalPeriods=\"+str(total_periods)\n",
    "            #Call API and put errors and responses into variables\n",
    "            response = requests.get(full_url, headers=header)\n",
    "            api_status_code, api_status_reason = response.status_code, response.reason #Get API call status & reasons for error\n",
    "            response = response.json()\n",
    "            #Define filename\n",
    "            file_name = state+\"_\"+suburb+\"_\"+postcode+\"_\"+year+\"_\"+str(api_status_code)+\"_\"+api_name+\"_\"+property_types\n",
    "            \n",
    "            #Convert json response to parquet file\n",
    "            df = pd.DataFrame(response)\n",
    "            df.to_parquet(file_name+\".parquet\")\n",
    "            \n",
    "            #Upload parquet files into S3 bucket\n",
    "            s3.upload_file(file_name+\".parquet\", parquetbucket, file_name+\".parquet\")\n",
    "            #os.remove(file_name+\".parquet\")\n",
    "            \n",
    "            #Upload json response into S3 bucket\n",
    "            df.to_json(file_name+\".json\")\n",
    "            #s3.put_object(Key=file_name+\".json\",Body=json.dumps(response), Bucket=jsonbucket)\n",
    "            #Set loop outcome to Success\n",
    "            loop_outcome = \"Success\"\n",
    "            #Logging - append each loop to list of lists\n",
    "            loop_log.append([api_name,seed_table,seed_key,full_url,api_status_code,api_status_reason,loop_outcome,api_call_datetime])            \n",
    "        except:\n",
    "            loop_outcome = \"Error\"\n",
    "            loop_log.append([api_name,seed_table,seed_key,full_url,api_status_code,api_status_reason,loop_outcome,api_call_datetime])            \n",
    "\n",
    "#Convert loop_log to dataframe and adjust datatypes\n",
    "loop_log_df = pd.DataFrame(loop_log, columns = ['API_NAME', 'SEED_TABLE', 'SEED_KEY', 'TARGET_URL', 'API_STATUS_CODE', 'API_STATUS_REASON','LOOP_OUTCOME','API_CALL_DATETIME'])\n",
    "loop_log_df['API_CALL_DATETIME'] = (loop_log_df[\"API_CALL_DATETIME\"]).astype(str)\n",
    "\n",
    "#Write loop_log_df to Snowflake API_CALL_LOG table\n",
    "success, nchunks, nrows, _ = write_pandas(ctx, loop_log_df, 'API_CALL_LOG')\n",
    "print(loop_log_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d768dd2128334442ca1e92e2788cb227a54429e0fad75b40fb8e40e4736d8a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
